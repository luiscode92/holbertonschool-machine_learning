# 0x05. Regularization
## Specializations - Machine Learning â€• Supervised Learning
## Objectives
* What is regularization? What is its purpose?
* What is are L1 and L2 regularization? What is the difference between the two methods?
* What is dropout?
* What is early stopping?
* What is data augmentation?
* How do you implement the above regularization methods in Numpy? Tensorflow?
* What are the pros and cons of the above regularization methods?

## Tasks
0. L2 Regularization Cost

1. Gradient Descent with L2 Regularization

2. L2 Regularization Cost

3. Create a Layer with L2 Regularization

4. Forward Propagation with Dropout

5. Gradient Descent with Dropout

6. Create a Layer with Dropout

7. Early Stopping

8. If you can't explain it to a six year old, you don't understand it yourself
